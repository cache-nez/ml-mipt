{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lasagne.layers.dnn\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from cifar import load_CIFAR10\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "\n",
    "cifar10_dir = './cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def cifar_to_augmentation(img):\n",
    "    return np.transpose(img, (1, 2, 0))\n",
    "\n",
    "def augmentation_to_cifar(img):\n",
    "    return np.transpose(img, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "#     iaa.Crop(px=(0, 1)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Sometimes(0.1, iaa.Crop(px=(0, 1))),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Sometimes(0.5, iaa.AdditiveGaussianNoise(scale=0.1*255)),\n",
    "    iaa.Sometimes(0.5, iaa.Affine(rotate=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from theano import tensor as T\n",
    "from lasagne.nonlinearities import *\n",
    "import lasagne.layers.dnn\n",
    "\n",
    "input_X = T.tensor4(\"X\")\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False, augment=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        if augment:\n",
    "            to_aug_x = map(cifar_to_augmentation, inputs[excerpt])\n",
    "            to_aug_x = np.array(list(to_aug_x))\n",
    "            to_aug_x = map(augmentation_to_cifar, seq.augment_images(to_aug_x))\n",
    "            inp = np.array(list(to_aug_x))\n",
    "        else:\n",
    "            inp = inputs[excerpt]\n",
    "        yield inp, targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "val_ind = random.sample(range(len(X_train)), len(X_train) // 5)\n",
    "X_val = X_train[val_ind]\n",
    "y_val = y_train[val_ind]\n",
    "X_train = np.delete(X_train, val_ind, axis=0)\n",
    "y_train = np.delete(y_train, val_ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def send(text):\n",
    "    import requests\n",
    "    telegram_token = '224136417:AAGJ2kKaoPiiksBVJ-8AslDTavFDL6btqqE'\n",
    "    requests.get('https://api.telegram.org/bot{}/sendMessage?chat_id=277146928&text={}'.format(telegram_token, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def iter_epoch(X_train, y_train, batch_size, train_fun, augment):\n",
    "    f = open('nn-output.txt', 'a')\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    cnt = 0\n",
    "    for batch in iterate_minibatches(X_train, y_train, batch_size, augment):\n",
    "        cnt += 1\n",
    "        if cnt % (len(X_train) // batch_size // 2) == 0:\n",
    "            print(epoch, cnt * batch_size / len(X_train))\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time), file=f)\n",
    "    send(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches), file=f)\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100), file=f)\n",
    "    send(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100), file=f)\n",
    "    send(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))\n",
    "    f.close()\n",
    "    \n",
    "def test():\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "        inputs, targets = batch\n",
    "        acc = accuracy_fun(inputs, targets)\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "        test_acc / test_batches * 100))\n",
    "    return  test_acc / test_batches * 100\n",
    "    \n",
    "def reset_net():\n",
    "    def add_normalized_conv(net, num_filters):\n",
    "        net = lasagne.layers.dnn.Conv2DDNNLayer(net, num_filters=num_filters, filter_size=(3, 3), pad='same', nonlinearity=lasagne.nonlinearities.identity)\n",
    "        net = lasagne.layers.dnn.BatchNormDNNLayer(net, epsilon=1e-3)\n",
    "        net = lasagne.layers.NonlinearityLayer(net)\n",
    "        return net\n",
    "\n",
    "    net = lasagne.layers.InputLayer(shape=(None, 3, 32, 32), input_var=input_X)\n",
    "\n",
    "    net = add_normalized_conv(net, 64)\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.3)\n",
    "    net = add_normalized_conv(net, 64)\n",
    "    net = lasagne.layers.dnn.MaxPool2DDNNLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    net = add_normalized_conv(net, 128)\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.4)\n",
    "    net = add_normalized_conv(net, 128)\n",
    "\n",
    "    net = add_normalized_conv(net, 256)\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.4)\n",
    "    net = add_normalized_conv(net, 256)\n",
    "    net = lasagne.layers.dnn.MaxPool2DDNNLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    net = add_normalized_conv(net, 512)\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.4)\n",
    "    net = add_normalized_conv(net, 512)\n",
    "    net = lasagne.layers.dnn.MaxPool2DDNNLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.5)\n",
    "    net = lasagne.layers.DenseLayer(net, 512)\n",
    "    net = lasagne.layers.dnn.BatchNormDNNLayer(net)\n",
    "    net = lasagne.layers.NonlinearityLayer(net)\n",
    "\n",
    "    net = lasagne.layers.DenseLayer(net, num_units = 10, nonlinearity=softmax)\n",
    "    \n",
    "    y_predicted = lasagne.layers.get_output(net)\n",
    "    all_weights = lasagne.layers.get_all_params(net, trainable=True)\n",
    "    return all_weights, y_predicted, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5\n",
      "0 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t38.98 %\n",
      "1 0.5\n",
      "1 1.0\n",
      "2 0.5\n",
      "2 1.0\n",
      "3 0.5\n",
      "3 1.0\n",
      "4 0.5\n",
      "4 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t65.74 %\n",
      "5 0.5\n",
      "5 1.0\n",
      "6 0.5\n",
      "6 1.0\n",
      "7 0.5\n",
      "7 1.0\n",
      "8 0.5\n",
      "8 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t72.57 %\n",
      "9 0.5\n",
      "9 1.0\n",
      "10 0.5\n",
      "10 1.0\n",
      "11 0.5\n",
      "11 1.0\n",
      "12 0.5\n",
      "12 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t76.50 %\n",
      "13 0.5\n",
      "13 1.0\n",
      "14 0.5\n",
      "14 1.0\n",
      "15 0.5\n",
      "15 1.0\n",
      "16 0.5\n",
      "16 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t78.54 %\n",
      "17 0.5\n",
      "17 1.0\n",
      "18 0.5\n",
      "18 1.0\n",
      "19 0.5\n",
      "19 1.0\n",
      "20 0.5\n",
      "20 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t79.34 %\n",
      "21 0.5\n",
      "21 1.0\n",
      "22 0.5\n",
      "22 1.0\n",
      "23 0.5\n",
      "23 1.0\n",
      "24 0.5\n",
      "24 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t78.97 %\n",
      "25 0.5\n",
      "25 1.0\n",
      "26 0.5\n",
      "26 1.0\n",
      "27 0.5\n",
      "27 1.0\n",
      "28 0.5\n",
      "28 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t79.89 %\n",
      "29 0.5\n",
      "29 1.0\n",
      "30 0.5\n",
      "30 1.0\n",
      "31 0.5\n",
      "31 1.0\n",
      "32 0.5\n",
      "32 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t80.59 %\n",
      "33 0.5\n",
      "33 1.0\n",
      "34 0.5\n",
      "34 1.0\n",
      "35 0.5\n",
      "35 1.0\n",
      "36 0.5\n",
      "36 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t80.56 %\n",
      "37 0.5\n",
      "37 1.0\n",
      "38 0.5\n",
      "38 1.0\n",
      "39 0.5\n",
      "39 1.0\n",
      "40 0.5\n",
      "40 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t80.86 %\n",
      "41 0.5\n",
      "41 1.0\n",
      "42 0.5\n",
      "42 1.0\n",
      "43 0.5\n",
      "43 1.0\n",
      "44 0.5\n",
      "44 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.38 %\n",
      "45 0.5\n",
      "45 1.0\n",
      "46 0.5\n",
      "46 1.0\n",
      "47 0.5\n",
      "47 1.0\n",
      "48 0.5\n",
      "48 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t80.90 %\n",
      "49 0.5\n",
      "49 1.0\n",
      "50 0.5\n",
      "50 1.0\n",
      "51 0.5\n",
      "51 1.0\n",
      "52 0.5\n",
      "52 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.57 %\n",
      "53 0.5\n",
      "53 1.0\n",
      "54 0.5\n",
      "54 1.0\n",
      "55 0.5\n",
      "55 1.0\n",
      "56 0.5\n",
      "56 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.37 %\n",
      "57 0.5\n",
      "57 1.0\n",
      "58 0.5\n",
      "58 1.0\n",
      "59 0.5\n",
      "59 1.0\n",
      "60 0.5\n",
      "60 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.13 %\n",
      "61 0.5\n",
      "61 1.0\n",
      "62 0.5\n",
      "62 1.0\n",
      "63 0.5\n",
      "63 1.0\n",
      "64 0.5\n",
      "64 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.59 %\n",
      "65 0.5\n",
      "65 1.0\n",
      "66 0.5\n",
      "66 1.0\n",
      "67 0.5\n",
      "67 1.0\n",
      "68 0.5\n",
      "68 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.47 %\n",
      "69 0.5\n",
      "69 1.0\n",
      "70 0.5\n",
      "70 1.0\n",
      "71 0.5\n",
      "71 1.0\n",
      "72 0.5\n",
      "72 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.89 %\n",
      "73 0.5\n",
      "73 1.0\n",
      "74 0.5\n",
      "74 1.0\n",
      "75 0.5\n",
      "75 1.0\n",
      "76 0.5\n",
      "76 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.57 %\n",
      "77 0.5\n",
      "77 1.0\n",
      "78 0.5\n",
      "78 1.0\n",
      "79 0.5\n",
      "79 1.0\n",
      "80 0.5\n",
      "80 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t82.31 %\n",
      "81 0.5\n",
      "81 1.0\n",
      "82 0.5\n",
      "82 1.0\n",
      "83 0.5\n",
      "83 1.0\n",
      "84 0.5\n",
      "84 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.83 %\n",
      "85 0.5\n",
      "85 1.0\n",
      "86 0.5\n",
      "86 1.0\n",
      "87 0.5\n",
      "87 1.0\n",
      "88 0.5\n",
      "88 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.95 %\n",
      "89 0.5\n",
      "89 1.0\n",
      "90 0.5\n",
      "90 1.0\n",
      "91 0.5\n",
      "91 1.0\n",
      "92 0.5\n",
      "92 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t82.58 %\n",
      "93 0.5\n",
      "93 1.0\n",
      "94 0.5\n",
      "94 1.0\n",
      "95 0.5\n",
      "95 1.0\n",
      "96 0.5\n",
      "96 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t81.97 %\n",
      "97 0.5\n",
      "97 1.0\n",
      "98 0.5\n",
      "98 1.0\n",
      "99 0.5\n",
      "99 1.0\n",
      "100 0.5\n",
      "100 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t82.74 %\n",
      "101 0.5\n",
      "101 1.0\n",
      "102 0.5\n",
      "102 1.0\n",
      "103 0.5\n",
      "103 1.0\n",
      "104 0.5\n",
      "104 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t82.81 %\n",
      "105 0.5\n",
      "105 1.0\n",
      "106 0.5\n",
      "106 1.0\n",
      "107 0.5\n",
      "107 1.0\n",
      "108 0.5\n",
      "108 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t82.27 %\n",
      "109 0.5\n",
      "109 1.0\n",
      "110 0.5\n",
      "110 1.0\n",
      "111 0.5\n",
      "111 1.0\n",
      "112 0.5\n",
      "112 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t82.81 %\n",
      "113 0.5\n",
      "113 1.0\n",
      "114 0.5\n",
      "114 1.0\n",
      "115 0.5\n",
      "115 1.0\n",
      "116 0.5\n",
      "116 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t82.78 %\n",
      "117 0.5\n",
      "117 1.0\n",
      "118 0.5\n",
      "118 1.0\n",
      "119 0.5\n",
      "119 1.0\n",
      "120 0.5\n",
      "120 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t82.47 %\n",
      "121 0.5\n",
      "121 1.0\n",
      "122 0.5\n",
      "122 1.0\n",
      "123 0.5\n",
      "123 1.0\n",
      "124 0.5\n",
      "124 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t82.08 %\n",
      "125 0.5\n",
      "125 1.0\n",
      "126 0.5\n",
      "126 1.0\n",
      "127 0.5\n",
      "127 1.0\n",
      "128 0.5\n",
      "128 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t83.05 %\n",
      "129 0.5\n",
      "129 1.0\n",
      "130 0.5\n",
      "130 1.0\n",
      "131 0.5\n",
      "131 1.0\n",
      "132 0.5\n",
      "132 1.0\n",
      "Final results:\n",
      "  test accuracy:\t\t83.02 %\n",
      "133 0.5\n",
      "133 1.0\n",
      "134 0.5\n"
     ]
    }
   ],
   "source": [
    "weights, y_predicted, net = reset_net()\n",
    "loss = lasagne.objectives.categorical_crossentropy(predictions=y_predicted, targets=target_y).mean()\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted, target_y).mean()\n",
    "\n",
    "learning_rate = theano.shared(lasagne.utils.floatX(1e-4))\n",
    "updates = lasagne.updates.adam(loss, weights, learning_rate=learning_rate) \n",
    "train_fun = theano.function([input_X, target_y],[loss, accuracy], updates=updates, allow_input_downcast=True)\n",
    "accuracy_fun = theano.function([input_X, target_y],\n",
    "                               accuracy, \n",
    "                               allow_input_downcast=True)\n",
    "augment_each_iter_net = {}\n",
    "\n",
    "num_epochs = 200 #количество проходов по данным\n",
    "batch_size = 20 #размер мини-батча\n",
    "send('NEW NETWORK')\n",
    "f = open('nn-output.txt', 'a')\n",
    "print('NEW NETWORK', file=f)\n",
    "for epoch in range(num_epochs):\n",
    "    iter_epoch(X_train, y_train, batch_size, train_fun, augment=True)\n",
    "    if epoch % 4 == 0:\n",
    "        send(\"  test accuracy:\\t\\t{:.2f} %\".format(test()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "На нормальном количестве эпох получилось на 3% больше :) А ещё была другая сетка:\n",
    "![title](nn2.png)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
