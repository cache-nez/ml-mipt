{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "Using gpu device 0: Tesla K80 (CNMeM is disabled, cuDNN 5110)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lasagne.layers.dnn\n",
    "import random\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from cifar import load_CIFAR10\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) \n",
    "\n",
    "cifar10_dir = './cifar10/cifar-10-batches-py'\n",
    "X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 3, 32, 32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cifar_to_augmentation(img):\n",
    "    return np.transpose(img, (1, 2, 0))\n",
    "\n",
    "def augmentation_to_cifar(img):\n",
    "    return np.transpose(img, (2, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from imgaug import augmenters as iaa\n",
    "\n",
    "seq = iaa.Sequential([\n",
    "#     iaa.Crop(px=(0, 1)), # crop images from each side by 0 to 16px (randomly chosen)\n",
    "    iaa.Sometimes(0.1, iaa.Crop(px=(0, 1))),\n",
    "    iaa.Fliplr(0.5),\n",
    "    iaa.Sometimes(0.5, iaa.AdditiveGaussianNoise(scale=0.1*255)),\n",
    "    iaa.Sometimes(0.5, iaa.Affine(rotate=5))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lasagne\n",
    "from theano import tensor as T\n",
    "from lasagne.nonlinearities import *\n",
    "import lasagne.layers.dnn\n",
    "\n",
    "input_X = T.tensor4(\"X\")\n",
    "target_y = T.vector(\"target Y integer\",dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iterate_minibatches(inputs, targets, batchsize, shuffle=False, augment=False):\n",
    "    assert len(inputs) == len(targets)\n",
    "    if shuffle:\n",
    "        indices = np.arange(len(inputs))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(inputs) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        if augment:\n",
    "            to_aug_x = map(cifar_to_augmentation, inputs[excerpt])\n",
    "            to_aug_x = np.array(list(to_aug_x))\n",
    "            to_aug_x = map(augmentation_to_cifar, seq.augment_images(to_aug_x))\n",
    "            inp = np.array(list(to_aug_x))\n",
    "        else:\n",
    "            inp = inputs[excerpt]\n",
    "        yield inp, targets[excerpt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_ind = random.sample(range(len(X_train)), len(X_train) // 5)\n",
    "X_val = X_train[val_ind]\n",
    "y_val = y_train[val_ind]\n",
    "X_train = np.delete(X_train, val_ind, axis=0)\n",
    "y_train = np.delete(y_train, val_ind, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def send(text):\n",
    "    import requests\n",
    "    telegram_token = ''\n",
    "    requests.get('https://api.telegram.org/bot{}/sendMessage?chat_id=277146928&text={}'.format(telegram_token, text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def iter_epoch(X_train, y_train, batch_size, train_fun, augment):\n",
    "    f = open('nn-output.txt', 'a')\n",
    "    # In each epoch, we do a full pass over the training data:\n",
    "    train_err = 0\n",
    "    train_acc = 0\n",
    "    train_batches = 0\n",
    "    start_time = time.time()\n",
    "    cnt = 0\n",
    "    for batch in iterate_minibatches(X_train, y_train, batch_size, augment):\n",
    "        cnt += 1\n",
    "        if cnt % (len(X_train) // batch_size // 2) == 0:\n",
    "            print(epoch, cnt * batch_size / len(X_train))\n",
    "        inputs, targets = batch\n",
    "        train_err_batch, train_acc_batch= train_fun(inputs, targets)\n",
    "        train_err += train_err_batch\n",
    "        train_acc += train_acc_batch\n",
    "        train_batches += 1\n",
    "\n",
    "    # And a full pass over the validation data:\n",
    "    val_acc = 0\n",
    "    val_batches = 0\n",
    "    for batch in iterate_minibatches(X_val, y_val, batch_size):\n",
    "        inputs, targets = batch\n",
    "        val_acc += accuracy_fun(inputs, targets)\n",
    "        val_batches += 1\n",
    "\n",
    "    # Then we print the results for this epoch:\n",
    "    print(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time), file=f)\n",
    "    send(\"Epoch {} of {} took {:.3f}s\".format(epoch + 1, num_epochs, time.time() - start_time))\n",
    "    print(\"  training loss (in-iteration):\\t\\t{:.6f}\".format(train_err / train_batches), file=f)\n",
    "    print(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100), file=f)\n",
    "    send(\"  train accuracy:\\t\\t{:.2f} %\".format(train_acc / train_batches * 100))\n",
    "    print(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100), file=f)\n",
    "    send(\"  validation accuracy:\\t\\t{:.2f} %\".format(val_acc / val_batches * 100))\n",
    "    f.close()\n",
    "    \n",
    "def test():\n",
    "    test_acc = 0\n",
    "    test_batches = 0\n",
    "    for batch in iterate_minibatches(X_test, y_test, 500):\n",
    "        inputs, targets = batch\n",
    "        acc = accuracy_fun(inputs, targets)\n",
    "        test_acc += acc\n",
    "        test_batches += 1\n",
    "    print(\"Final results:\")\n",
    "    print(\"  test accuracy:\\t\\t{:.2f} %\".format(\n",
    "        test_acc / test_batches * 100))\n",
    "    return  test_acc / test_batches * 100\n",
    "    \n",
    "def reset_net():\n",
    "    def add_normalized_conv(net, num_filters):\n",
    "        net = lasagne.layers.dnn.Conv2DDNNLayer(net, num_filters=num_filters, filter_size=(3, 3), pad='same', nonlinearity=lasagne.nonlinearities.identity)\n",
    "        net = lasagne.layers.dnn.BatchNormDNNLayer(net, epsilon=1e-3)\n",
    "        net = lasagne.layers.NonlinearityLayer(net)\n",
    "        return net\n",
    "\n",
    "    net = lasagne.layers.InputLayer(shape=(None, 3, 32, 32), input_var=input_X)\n",
    "\n",
    "    net = add_normalized_conv(net, 64)\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.3)\n",
    "    net = add_normalized_conv(net, 64)\n",
    "    net = lasagne.layers.dnn.MaxPool2DDNNLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    net = add_normalized_conv(net, 128)\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.4)\n",
    "    net = add_normalized_conv(net, 128)\n",
    "\n",
    "    net = add_normalized_conv(net, 256)\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.4)\n",
    "    net = add_normalized_conv(net, 256)\n",
    "    net = lasagne.layers.dnn.MaxPool2DDNNLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    net = add_normalized_conv(net, 512)\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.4)\n",
    "    net = add_normalized_conv(net, 512)\n",
    "    net = lasagne.layers.dnn.MaxPool2DDNNLayer(net, pool_size=(2, 2))\n",
    "\n",
    "    net = lasagne.layers.dropout_channels(net, p=0.5)\n",
    "    net = lasagne.layers.DenseLayer(net, 512)\n",
    "    net = lasagne.layers.dnn.BatchNormDNNLayer(net)\n",
    "    net = lasagne.layers.NonlinearityLayer(net)\n",
    "\n",
    "    net = lasagne.layers.DenseLayer(net, num_units = 10, nonlinearity=softmax)\n",
    "    \n",
    "    y_predicted = lasagne.layers.get_output(net)\n",
    "    all_weights = lasagne.layers.get_all_params(net, trainable=True)\n",
    "    return all_weights, y_predicted, net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.5\n",
      "0 1.0\n",
      "1 0.5\n",
      "1 1.0\n",
      "2 0.5\n",
      "2 1.0\n",
      "3 0.5\n",
      "3 1.0\n",
      "4 0.5\n",
      "4 1.0\n",
      "5 0.5\n",
      "5 1.0\n",
      "6 0.5\n",
      "6 1.0\n",
      "7 0.5\n",
      "7 1.0\n",
      "8 0.5\n",
      "8 1.0\n",
      "9 0.5\n",
      "9 1.0\n",
      "10 0.5\n",
      "10 1.0\n",
      "11 0.5\n",
      "11 1.0\n",
      "12 0.5\n",
      "12 1.0\n",
      "13 0.5\n",
      "13 1.0\n",
      "14 0.5\n",
      "14 1.0\n",
      "15 0.5\n",
      "15 1.0\n",
      "16 0.5\n",
      "16 1.0\n",
      "17 0.5\n",
      "17 1.0\n",
      "18 0.5\n",
      "18 1.0\n",
      "19 0.5\n",
      "19 1.0\n",
      "20 0.5\n",
      "20 1.0\n",
      "21 0.5\n",
      "21 1.0\n",
      "22 0.5\n",
      "22 1.0\n",
      "23 0.5\n",
      "23 1.0\n",
      "24 0.5\n",
      "24 1.0\n",
      "25 0.5\n",
      "25 1.0\n",
      "26 0.5\n",
      "26 1.0\n",
      "27 0.5\n",
      "27 1.0\n",
      "28 0.5\n",
      "28 1.0\n",
      "29 0.5\n",
      "29 1.0\n",
      "30 0.5\n",
      "30 1.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-d02dd3f4ea21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'NEW NETWORK'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0miter_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-23-2dc5aca52de4>\u001b[0m in \u001b[0;36miter_epoch\u001b[0;34m(X_train, y_train, batch_size, train_fun, augment)\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mtrain_err_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mtrain_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_err\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_err_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_acc\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtrain_acc_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "weights, y_predicted, net = reset_net()\n",
    "loss = lasagne.objectives.categorical_crossentropy(predictions=y_predicted, targets=target_y).mean()\n",
    "accuracy = lasagne.objectives.categorical_accuracy(y_predicted, target_y).mean()\n",
    "\n",
    "learning_rate = theano.shared(lasagne.utils.floatX(1e-4))\n",
    "updates = lasagne.updates.adam(loss, weights, learning_rate=learning_rate) \n",
    "train_fun = theano.function([input_X, target_y],[loss, accuracy], updates=updates, allow_input_downcast=True)\n",
    "accuracy_fun = theano.function([input_X, target_y],\n",
    "                               accuracy, \n",
    "                               allow_input_downcast=True)\n",
    "augment_each_iter_net = {}\n",
    "\n",
    "num_epochs = 200 #количество проходов по данным\n",
    "batch_size = 20 #размер мини-батча\n",
    "send('NEW NETWORK')\n",
    "f = open('nn-output.txt', 'a')\n",
    "print('NEW NETWORK', file=f)\n",
    "for epoch in range(num_epochs):\n",
    "    iter_epoch(X_train, y_train, batch_size, train_fun, augment=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не успевала обучить дольше :с Сервер только на два дня - неприятно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final results:\n",
      "  test accuracy:\t\t80.66 %\n"
     ]
    }
   ],
   "source": [
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Achievement unlocked: колдун 80 уровня\n"
     ]
    }
   ],
   "source": [
    "acc = test()\n",
    "if acc > 80:\n",
    "    print(\"Achievement unlocked: колдун 80 уровня\")\n",
    "else:\n",
    "    print(\"Нужно больше магии\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
